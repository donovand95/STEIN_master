{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d, interp2d\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from IPython.display import display, clear_output\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from jupyterthemes import jtplot\n",
    "import time\n",
    "import scipy as scipy\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import csv\n",
    "\n",
    "jtplot.style(theme = 'gruvboxd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenarios = 10\n",
    "# total_time = 50\n",
    "# sample_no = 30\n",
    "# SLHL_C14 = 14.1\n",
    "# SLHL_Be10 = 4.1\n",
    "# SLHL_He3 = 120.5\n",
    "# scaling_factor = 1.1\n",
    "# stoch_base_ER = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth = [350,1500]\n",
    "# # dat_lin = np.arange(0,max_depth,1)\n",
    "# rock_rho = 2.7\n",
    "# CN_lambda = 160\n",
    "# mu = rock_rho/ CN_lambda\n",
    "# dt = 1\n",
    "# MAT = 0\n",
    "# T_AMP = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rock_rho = 2.7\n",
    "# CN_lambda = 160\n",
    "# mu = rock_rho / CN_lambda\n",
    "# dt = 1\n",
    "\n",
    "# # He diffusion inputs\n",
    "# rho = 2.65 # quartz density\n",
    "# nx = 100\n",
    "# r = 0.1\n",
    "# dx = (r / nx)\n",
    "# x = np.arange(dx/2, r, dx)\n",
    "# x_up = x + (dx/2)\n",
    "# x_low = x - (dx/2)\n",
    "# x_vol = [(4/3 * np.pi * x_up[i]**3) - (4/3 * np.pi * x_low[i]**3) for i in range(len(x))]\n",
    "# shell_mass = [(x_vol[i] * rho) for i in range(len(x_vol))]\n",
    "\n",
    "# # Bedrock thermal properties\n",
    "# alpha = 1.5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ER_import(stoch_base_ER):\n",
    "    read_in = open('D:/STEIN_paper/model_outputs/stochastic_erosion/erosion_sets/import_dates.csv')\n",
    "    myreader = csv.reader(read_in)\n",
    "    \n",
    "    for row in myreader:\n",
    "        mat_gen_dates = row[:]\n",
    "    \n",
    "    ERs = np.genfromtxt('D:/STEIN_paper/model_outputs/stochastic_erosion/erosion_sets/ER_list_' + str(stoch_base_ER) + '_' + str(mat_gen_dates[-1]) + '.csv',\n",
    "                                  delimiter = ',')\n",
    "        \n",
    "    return ERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def CN_stoch_in_fxn(ERs_all):\n",
    "    CN_import = np.empty((total_time, 4, scenarios))\n",
    "    for i in range(scenarios):\n",
    "        CN_import[:,:3,i] = np.genfromtxt('D:/STEIN_paper/model_outputs/stochastic_erosion/STO_C14_Be10_ER' + str(ERs_all[i]) + '_expmat.csv', \n",
    "                                          delimiter = ',')\n",
    "\n",
    "        CN_import[:,3,i] = np.genfromtxt('D:/STEIN_paper/model_outputs/stochastic_erosion/STO_He3_ER' + str(ERs_all[i]) + '_surfmat.csv',\n",
    "                              delimiter = ',')\n",
    "        \n",
    "    return CN_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def sampling_fxn(CN_import_matrix, sample_no, scenarios):\n",
    "    P0_Be10 = SLHL_Be10 * scaling_factor\n",
    "    P0_He3 = SLHL_Be10 * scaling_factor\n",
    "    sampling_years = np.sort(np.random.choice(np.arange(int(total_time * 0.1),total_time),sample_no))\n",
    "    sampling_mat = np.empty((sample_no, 5, scenarios))\n",
    "    measured = np.empty((5,scenarios))\n",
    "    \n",
    "    for j in range(scenarios):\n",
    "        \n",
    "        sampling_14C = []\n",
    "        sampling_Be = []\n",
    "        sampling_rat = []\n",
    "        sampling_3He = []\n",
    "    \n",
    "        for i in range(sample_no):           \n",
    "\n",
    "            sampling_14C.append(CN_import_matrix[sampling_years[i],0,j])\n",
    "            sampling_Be.append(CN_import_matrix[sampling_years[i],1,j])\n",
    "            sampling_rat.append(CN_import_matrix[sampling_years[i],2,j])\n",
    "            sampling_3He.append(CN_import_matrix[sampling_years[i],3,j])\n",
    "        \n",
    "        sampling_mat[:,0,j] = sampling_14C\n",
    "        sampling_mat[:,1,j] = sampling_Be\n",
    "        sampling_mat[:,2,j] = sampling_rat\n",
    "        sampling_mat[:,3,j] = sampling_3He\n",
    "        sampling_mat[:,4,j] = sampling_years \n",
    "        \n",
    "        measured[0,j] = np.mean(sampling_mat[:,0,j])\n",
    "        measured[1,j] = np.mean(sampling_mat[:,1,j])\n",
    "        measured[2,j] = measured[0,j] / measured[1,j]\n",
    "        measured[3,j] = np.mean(sampling_mat[:,4,j])\n",
    "        measured[4,j] = (np.mean(sampling_mat[:,4,j]) / np.mean(sampling_mat[:,1])) * (P0_Be10 / P0_He3)\n",
    "        \n",
    "    measured_ER = [(160 / 2.62 * P0_Be10 / measured[1,j]) for j in range(scenarios)]\n",
    "    \n",
    "    return sampling_mat, measured, measured_ER  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generate_constant_comps(measured_ER):\n",
    "    %run D:\\STEIN_paper\\model_outputs\\scripts\\C14_Be10_constant_erosion_for_stoch_compare.ipynb\n",
    "    %run D:\\STEIN_paper\\model_outputs\\scripts\\He3_constant_erosion_for_stoch_compare.ipynb\n",
    "    \n",
    "    comp_mat = np.empty((total_time, 5, scenarios))\n",
    "    \n",
    "    shift_ER = False\n",
    "    save_only_surf = True\n",
    "    save_output = True    \n",
    "    \n",
    "    for i in range(scenarios):\n",
    "        \n",
    "        initial_ER = measured_ER[i]\n",
    "        comp_mat[:,2,i], comp_mat[:,0,i], comp_mat[:,1,i] = CRN_comp_loop_fxn(total_time, initial_ER)[2:5] \n",
    "        comp_mat[:,3,i] = He3_comp_loop_fxn(total_time, initial_ER)\n",
    "        comp_mat[:,4,i] = np.divide(comp_mat[:,3,i], comp_mat[:,1,i]) * P0_Be10 / P0_He3\n",
    "        \n",
    "    return comp_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compare_fxn():\n",
    "    \n",
    "    ERs_all = ER_import(stoch_base_ER)\n",
    "    CN_import = CN_stoch_in_fxn(ERs_all)\n",
    "    samples, measured, measured_ER = sampling_fxn(CN_import, sample_no, scenarios)\n",
    "    const_comp_mat = generate_constant_comps(measured_ER)\n",
    "    \n",
    "    return const_comp_mat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
